# -*- coding: utf-8 -*-
"""LR_Sentiment_Model_cmatrix_improved.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1GYVzR0tVmTCNDD38GjISy8Dzr5kbNeF3
"""

import numpy as np
import pandas as pd
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.ensemble import VotingClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.naive_bayes import MultinomialNB
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score
from sklearn.metrics import confusion_matrix  # Added for confusion matrix
import re
import nltk
from nltk.corpus import stopwords
from nltk.stem import WordNetLemmatizer
import seaborn as sns  # Added for visualization
import matplotlib.pyplot as plt  # Added for visualization

# Download stopwords and lemmatizer data
nltk.download('stopwords')
nltk.download('wordnet')

from google.colab import files
uploaded = files.upload()

import io
data = pd.read_excel(io.BytesIO(uploaded['data.xlsx']))
data

# Preprocessing function for cleaning and preprocessing the text
def preprocess_text(text):
    # Remove special characters and numbers
    text = re.sub(r'[^a-zA-Z]', ' ', text)

    # Convert text to lowercase
    text = text.lower()

    # Tokenize the text
    tokens = text.split()

    # Remove stopwords
    stop_words = set(stopwords.words('english'))
    tokens = [word for word in tokens if word not in stop_words]

    # Lemmatization
    lemmatizer = WordNetLemmatizer()
    tokens = [lemmatizer.lemmatize(word) for word in tokens]

    # Join the tokens back into a single string
    preprocessed_text = ' '.join(tokens)

    return preprocessed_text

# Apply the preprocessing function to the NPS comments
data['NPS Comment'] = data['NPS Comment'].apply(preprocess_text)

# Initialize the TF-IDF vectorizer
vectorizer = TfidfVectorizer(stop_words='english', max_features=100000, ngram_range=(1, 3))

# Vectorize the text data
X = vectorizer.fit_transform(data['NPS Comment'])
y = data['Sentiment']

# Initialize the individual classifiers
classifier1 = LogisticRegression()
classifier2 = MultinomialNB()
classifier3 = RandomForestClassifier()

# Create an ensemble of classifiers using majority voting
ensemble_classifier = VotingClassifier(estimators=[('lr', classifier1), ('nb', classifier2), ('rf', classifier3)], voting='hard')

# Train the ensemble classifier
ensemble_classifier.fit(X, y)

# Function to predict sentiment for new comments
def predict_sentiment(new_comments):
    # Preprocess the new comments
    preprocessed_comments = [preprocess_text(comment) for comment in new_comments]

    # Vectorize the preprocessed comments
    X_new = vectorizer.transform(preprocessed_comments)

    # Predict the sentiment for the new comments
    y_pred = ensemble_classifier.predict(X_new)

    return y_pred

# Evaluate the model's performance on the labeled data
y_pred_train = ensemble_classifier.predict(X)

from sklearn.metrics import confusion_matrix

# Calculate the confusion matrix
conf_matrix = confusion_matrix(y, y_pred_train)

# Create a DataFrame for the confusion matrix with class names
conf_matrix_df = pd.DataFrame(conf_matrix, index=data['Sentiment'].unique(), columns=data['Sentiment'].unique())

# Plot the confusion matrix
plt.figure(figsize=(8, 6))
sns.heatmap(conf_matrix_df, annot=True, fmt='d', cmap='Blues')
plt.xlabel('Predicted')
plt.ylabel('Actual')
plt.title('Confusion Matrix')
plt.show()

# Calculate performance metrics for multi-class classification
from sklearn.metrics import classification_report

classification_rep = classification_report(y, y_pred_train, target_names=data['Sentiment'].unique())
print("Classification Report:")
print(classification_rep)

# Calculate and display model accuracy, precision, and recall
accuracy = accuracy_score(y, y_pred_train)
precision = precision_score(y, y_pred_train, average='weighted')
recall = recall_score(y, y_pred_train, average='weighted')

print(f"Accuracy: {accuracy:.2f}")
print(f"Precision: {precision:.2f}")
print(f"Recall: {recall:.2f}")

# Print the confusion matrix
print("Confusion Matrix:")
print(conf_matrix)
print()

# Example usage
new_comments = [
    "CompanyXYZ is unable to solve issues. All 4 vessels in Australia currently have connection issues of some sort, and CompanyXYZ is slow, unresponsive, and unable to provide any solutions.",
    "Good",
    "Not at all",
    "Not at all good"
]

predicted_sentiment = predict_sentiment(new_comments)

for comment, sentiment in zip(new_comments, predicted_sentiment):
    print(f"Comment: {comment}")
    print(f"Predicted Sentiment: {sentiment}")
    print()